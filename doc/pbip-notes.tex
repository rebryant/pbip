\documentclass{easychair}
%\documentclass[runningheads]{llncs}

\usepackage{latexsym}
%\usepackage{times}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{pict2e}
\usepackage{tikz}
%%\usepackage{pgfplots}
%%\pgfplotsset{compat=1.14}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{marvosym}
%\usepackage{hyperref}
%% Colored hyperlink 
\newcommand{\cref}[2]{\href{#1}{\color{blue}#2}}
%% Colored hyperlink showing link in TT font
% \newcommand{\chref}[1]{\href{#1}{\small\tt \color{blue}#1}}
\newcommand{\hcref}[1]{\cref{#1}{\small\tt #1}}
%% Change tt font
\usepackage{inconsolata}
\usepackage[T1]{fontenc}
\usepackage{alltt}
%% ccode- for displaying formatted C code (c2tex) 
\newenvironment{ccode}%
{\begin{alltt}}%
{\end{alltt}}

\bibliographystyle{abbrv}
%\bibliographystyle{splncs04}

%% Putting labels in pictures
\newcommand{\booland}{\land}
\newcommand{\boolor}{\lor}
\newcommand{\boolxor}{\oplus}
\newcommand{\boolnot}{\neg}
\newcommand{\tautology}{\top}
\newcommand{\nil}{\bot}
\renewcommand{\obar}[1]{\overline{#1}}
\newcommand{\lit}{\ell}
\newcommand{\ite}{\mbox{\it ITE}}
\newcommand{\restrict}[2]{#1|_{#2}}
\newcommand{\trust}[1]{\dot {#1}}
\newcommand{\assign}{\rho}
\newcommand{\simplify}[2]{#1|_{#2}}
\newcommand{\nassign}{\obar{\assign}}
\newcommand{\indices}{I}
\newcommand{\unit}{\mathit{Unit}}
\newcommand{\uprop}{\mathit{Uprop}}
\newcommand{\imply}{\Rightarrow}


\newcommand{\opname}[1]{\mbox{\sc #1}}
\newcommand{\andop}{\opname{And}}
\newcommand{\implyop}{\opname{Imply}}

\newcommand{\applyand}{\opname{ApplyAnd}}
\newcommand{\applyor}{\opname{ApplyOr}}
\newcommand{\applyimply}{\opname{ProveImplication}}

\newcommand{\turnstile}{\models}
\newcommand{\func}[1]{\llbracket#1\rrbracket}

\newcommand{\fname}[1]{\mbox{\small\sf #1}}

\newcommand{\lo}{\fname{Lo}}
\newcommand{\hi}{\fname{Hi}}
\newcommand{\var}{\fname{Var}}
\newcommand{\val}{\fname{Val}}
\newcommand{\xvar}[1]{#1}
\newcommand{\node}[1]{\mathbf{#1}}
\newcommand{\nodeu}{\node{u}}
\newcommand{\nodev}{\node{v}}
\newcommand{\nodew}{\node{w}}

% Code formatting
\newcommand{\showcomment}[1]{\texttt{/*} \textit{#1} \texttt{*/}}
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\keyif}{\keyword{if}}
\newcommand{\keyfor}{\keyword{for}}
\newcommand{\keyelse}{\keyword{else}}
\newcommand{\keyor}{\keyword{or}}
\newcommand{\keyreturn}{\keyword{return}}
%\newcommand{\assign}{\ensuremath{\longleftarrow}}

\definecolor{redorange}{rgb}{0.878431, 0.235294, 0.192157}
\definecolor{lightblue}{rgb}{0.552941, 0.72549, 0.792157}
\definecolor{clearyellow}{rgb}{0.964706, 0.745098, 0}
\definecolor{clearorange}{rgb}{0.917647, 0.462745, 0}
\definecolor{mildgray}{rgb}{0.54902, 0.509804, 0.47451}
\definecolor{softblue}{rgb}{0.643137, 0.858824, 0.909804}
\definecolor{bluegray}{rgb}{0.141176, 0.313725, 0.603922}
\definecolor{lightgreen}{rgb}{0.709804, 0.741176, 0}
\definecolor{darkgreen}{rgb}{0.152941, 0.776471, 0.172549}
\definecolor{redpurple}{rgb}{0.835294, 0, 0.196078}
\definecolor{midblue}{rgb}{0, 0.592157, 0.662745}
\definecolor{clearpurple}{rgb}{0.67451, 0.0784314, 0.352941}
\definecolor{browngreen}{rgb}{0.333333, 0.313725, 0.145098}
\definecolor{darkestpurple}{rgb}{0.396078, 0.113725, 0.196078}
\definecolor{greypurple}{rgb}{0.294118, 0.219608, 0.298039}
\definecolor{darkturquoise}{rgb}{0, 0.239216, 0.298039}
\definecolor{darkbrown}{rgb}{0.305882, 0.211765, 0.160784}
\definecolor{midgreen}{rgb}{0.560784, 0.6, 0.243137}
\definecolor{darkred}{rgb}{0.576471, 0.152941, 0.172549}
\definecolor{darkpurple}{rgb}{0.313725, 0.027451, 0.470588}
\definecolor{darkestblue}{rgb}{0, 0.156863, 0.333333}
\definecolor{lightpurple}{rgb}{0.776471, 0.690196, 0.737255}
\definecolor{softgreen}{rgb}{0.733333, 0.772549, 0.572549}
\definecolor{offwhite}{rgb}{0.839216, 0.823529, 0.768627}


\title{Notes on \\ Pseudo-Boolean Implication Proofs \\ Version of \today}

\author{Randal E. Bryant}
\institute{
Computer Science Department \\
Carnegie Mellon University, Pittsburgh, PA, United States\\
\email{Randy.Bryant@cs.cmu.edu}
}


\begin{document}

\maketitle

This notes describes some ideas on converting unsatisfiability proofs
for pseudo-Boolean (PB) constraints into clausal proofs based on the
DRAT proof system.

\section{Background}

This section gives brief definitions of pseudo-Boolean constraints and their properties.
A more extensive introduction is provided by Gocht in his PhD thesis [Gocht-Phd-2022].

Consider a set of Boolean variables $X$.  For $x \in X$, {\em literal}
$\lit$ can denote either $x$ or its negation, written $\obar{x}$.  We
write $\obar{\lit}$ to denote $\obar{x}$ when $\lit = x$ and $x_i$ when
$\lit = \obar{x}$.

A {\em pseudo-Boolean constraint} is a linear expression, viewing
Boolean variables as ranging over integer values $0$ and $1$.  That
is, 
a constraint $C$ has the form
\begin{eqnarray}
\sum_{1 \leq i \leq n} a_i \lit_i & \# & b \label{eqn:pbconstraint}
\end{eqnarray}
where: 1) the relational operator $\#$ is $<$, $\leq$, $=$, $\geq$, or
$>$, and 2) the coefficients $a_i$, as well as the constant $b$, are
integers.
Constraints with relational operator $=$ are referred to as {\em equational constraints},
while others are referred to as {\em ordering constraints}.

Constraint $C$ denotes a Boolean function, written
$\func{C}$, mapping assignments to the set of variables $X$ to $1$
(true) or $0$ (false).  Constraints $C_1$ and $C_2$ are said to {\em
  equivalent} when $\func{C_1} = \func{C_2}$.
Constraint $C$ is said to be {\em infeasible} when $\func{C} = \bot$, i.e., it always evaluates $0$.
$C$ is said to be {\em trivial} when $\func{C} = \top$, i.e., it always evaluates to $1$.


As described in [Gocht-Phd-2022], the following are some properties of pseudo-Boolean constraints:
\begin{itemize}
\item Constraints with relational operators $<$, $\leq$, and $>$ can be
  converted to equivalent constraints with relational operator $\geq$.
\item
The logical negation of an ordering constraint $C$, written $\obar{C}$,
can also be expressed as a constraint.  That is, assume that $C$
has been converted to a form where it has relational operator $\geq$.
Then replacing $\geq$ by $<$ yields the negation of $C$.  
\item
A constraint $C$ with relational operator $=$ can be converted to the
pair of constraints $C_{\leq}$ and $C_{\geq}$, formed by replacing
$\#$ in (\ref{eqn:pbconstraint}) by $\leq$ and $\geq$, respectively.
These then satisfy $\func{C} = \func{C_{\leq}} \land \func{C_{\geq}}$.
\end{itemize}
We will generally
assume that constraints have relational operator $\geq$, since other
forms can be translated to it.  In some contexts, however, we will
maintain equational constraints 
intact, to avoid replacing it by two ordering constraints.


We consider two {\em normalized forms} for ordering constraints: A
{\em coefficient-normalized} constraint has only nonnegative
coefficients.  By convention, we require with this form that literal $\lit_i = x_i$ for any $i$ such that $a_i = 0$.
A {\em variable-normalized} constraint has only
positive literals.  Converting between the two forms is
straightforward using the identity $\obar{x}_i = 1-x_i$.  In reasoning
about PB constraints, the two forms can be used interchangeably.
Typically, the coefficient-normalized form is more convenient when
viewing a PB constraint as a logical expression, while the
variable-normalized form is more convenient when viewing a constraint
as an arithmetic expression.  In this document, we focus on the logical
aspects, giving the general form of constraint $C$ as
\begin{eqnarray}
\sum_{1 \leq i \leq n} a_{i} \lit_{i} & \geq & b \label{eqn:coeff-normalized}
\end{eqnarray}
with each $a_{i} \geq 0$, and with $\lit_{i} = x_i$ whenever $a_i = 0$.

Ordering constraint $C$ in coefficient-normalized form is trivial if and only
if $b \leq 0$.  Similarly, $C$ is infeasible if and only if
$b > \sum_{1 \leq i \leq n} {a_{i}}$.  By contrast, testing feasibility or triviality
of an equational constraint is not straightforward, in that an instance of the
subset sum problem [Garey] can be directly encoded as an equational
constraint.

An {\em assignment} is a mapping $\assign : X' \rightarrow \{0,1\}$,
for some $X' \subseteq X$.  The assignment is {\em total} when $X' =
X$ and {\em partial} when $X' \subset X$.  Assignment $\assign$ can
also be viewed as a set of literals, where $x_i \in \assign$ when
$\assign(x_i) = 1$ and $\obar{x}_i \in \assign$ when $\assign(x_i) = 0$.

Some nomenclature regarding constraints of the form of
(\ref{eqn:coeff-normalized}) will prove useful.  The {\em constraint
  literals} are those literals $\lit_i$ such that $a_i \not = 0$.  A
{\em cardinality constraint} has $a_i \in \{0,1\}$ for $1 \leq i \leq
n$.  A cardinality constraint with $b=1$ is referred to as a {\em
  clause}: at least one of the constraint literals must be assigned 1
to satisfy the constraint.  A cardinality constraint with $\sum_{1\leq
  i\leq n} a_i = b$ is referred to as a {\em conjunction}: all of the
constraint literals must be assigned $1$ to satisfy the constraint.
Observe that any assignment $\assign$ can be viewed as a conjunction,
having coefficient $a_i = 1$ for each $\lit_i \in \assign$.  A
conjunction with for which $a_i = 1$ for just a single value of $i$ is
referred to as a {\em unit} constraint: it is satisfied if and only if
literal $\lit_i$ is assigned $1$.


%% Note that for
%% assignments $\assign_1$ and $\assign_2$ over disjoint sets of
%% variables $X_1$ and $X_2$, their union is logically equivalent to
%% their conjunction: $\func{\assign_1 \cup \assign_2} = \func{\assign_1}
%% \land \func{\assign_2}$.

%% We shall make use of constraints representing the negations of
%% assignments.  That is, the negation of assignment $\assign$, written
%% $\nassign$, is the clause:
%% $\sum_{\lit_i \in \assign} \obar{\lit}_i \;\geq\; 1$.

We let $\simplify{C}{\assign}$ denote the constraint resulting when $C$ is
simplified according assignment $\assign$.  That is, assume $\assign$ is defined over a set of variables $X'$ and
partition the indices $i$ for $1 \leq i \leq n$ into
three sets:
$I^{+}$, consisting of those indices $i$ such that $\lit_{i} \in \assign$,
$I^{-}$, consisting of those indices $i$ such that $\obar{\lit}_{i} \in \assign$,
and $I^{X}$ consisting of those indices $i$ such that $x_i \not \in X'$.
With this, $\simplify{C}{\assign}$ can be written as $\sum_{1 \leq i \leq n} a'_i \; \geq \; b'$
with $a'_i$ equal to $a_i$ for $i \in I^{X}$ and equal to $0$ otherwise, and with $b' = b - \sum_{i\in I^{+}} a_i$.


%% \begin{eqnarray}
%% \sum_{i \in I^{X}} a_{i} \lit_{i} & \geq & b - \sum_{i \in I^{+}} a_{i} \label{eqn:assigned}
%% \end{eqnarray}

%% **** This looks fishy ****
%% We will find cases where we want to condition a constraint $C$ based
%% on a partial assignment $\assign$, expressing the constraint $\assign
%% \imply C$.  In particular, if constraint $C$ is of the form
%% (\ref{eqn:coeff-normalized}), then $\assign \imply C$ can be written as the PB constraint
%% \begin{eqnarray}
%% \sum_{\lit_i \in \assign} b\, \obar{\lit}_i \;\; + \;\;  \sum_{1 \leq i \leq n} a_{i} \lit_{i} & \geq & b \label{eqn:implication}
%% \end{eqnarray}

A pseudo-Boolean {\em formula} $F$ is a set of pseudo-Boolean
constraints.  We say that $F$ is {\em satisfiable} when there is some
assignment $\assign$ that satisfies all of the constraints in $F$, and
{\em unsatisfiable} otherwise.  



\section{(Reverse) Unit Propagation}

Consider constraint $C$ in coefficient-normalized form.  Literal
$\lit$ is {\em unit propagated} by $C$ when the assignment $\assign =
\{ \obar{\lit} \}$ causes the constraint $\simplify{C}{\assign}$ to become
infeasible.  As the name implies, a unit-propagated literal $\lit$ then becomes a unit constraint.
Observe that a single constraint can unit propagate
multiple literals.  For example, $4 x_1 + 3 \obar{x}_2 + x_3 \geq 6$
unit propagates both $x_1$ and $\obar{x}_2$.
For an ordering constraint $C$ in coefficent-normalized form
(\ref{eqn:coeff-normalized}), detecting which literals unit propagate
is straightforward.  Let $A = \sum_{1 \leq i \leq n} a_{i}$.  Then
literal $\lit_{i}$ unit propagates if and only if $A - a_{i} < b$,
i.e., $a_{i} > A - b$.  For example, the constraint $4 x_1 + 3
\obar{x}_2 + x_3 \geq 6$ has $A = 7$ and $b=6$, yielding $A-b=1$.
This justifies the unit propagations of both $x_1$ and $\obar{x}_2$.

For constraint $C$, we let $\unit(C)$ denote the set of literals it
unit propagates.  Often, by simplifying a constraint $C$ according to
a partial assignment $\assign$, the simplified constraint $\simplify{C}{\assign}$
will unit propagate new literals, given by $\unit(\simplify{C}{\assign})$.  These
literals can then be added to the partial assignment.  Formally,
define the operation $\uprop$ as  $\uprop(\assign, C) = \assign \cup \unit(\simplify{C}{\assign})$.
{\em Unit propagation} is then the process of
repeatedly applying this operation to a set of clauses to expand the
set of literals in a partial assignment.

Consider a formula $F$ consisting of a set of constraints $C_1, C_2,
\ldots, C_m$.  The {\em reverse unit propagation} (RUP) proof rule
      [Gocht-Phd-2022] uses unit propagation to prove that
      \emph{target constraint} $C$ can be added to a formula while
      preserving its set of satisfying assignments.  That is, any
      assignment that satisfies $F$ also satisfies $F \land C$.  RUP
      justifies $C$ by assuming $\obar{C}$ holds and showing, via a
      sequence of \emph{RUP steps}, that this leads to a
      contradiction.  It accumulates a partial assignment $\assign$
      based on unit propagations starting the empty set.
      Each RUP step accumulates more assigned
      literals by performing a unit propagation of the form $\assign
      \leftarrow \uprop(\assign, D)$, where constraint $D$ is either
      $C_j$, a prior constraint, or $\obar{C}$, the negation of the
      target constraint.  The final step causes a contradiction,
      where $\simplify{D}{\assign}$ is infeasbile.


\subsection{RUP Example}

As an example, consider the following three constraints:
\begin{center}
  \begin{tabular}{cllllll}
\toprule    
\makebox[1cm]{ID} & \multicolumn{6}{c}{Constraint} \\
\midrule
$C_1$ & \makebox[0.6cm][l]{$x_1$} & $+$ & \makebox[0.6cm][l]{$2 x_2$} & $+$ & \makebox[0.6cm][l]{$\obar{x}_3$} & \makebox[0.6cm][l]{$\geq 2$} \\
$C_2$ & $\obar{x}_1$ & $+$ & $\obar{x}_2$ & $+$ & $2 x_3$ & $\geq 2$ \\
$C_3$ & $x_1$ & $+$ & $2 \obar{x}_2$ & $+$ &  $3 \obar{x}_3$ & $\geq 3$ \\
\bottomrule
\end{tabular}
\end{center}
Our goal is to add the constraint $C = 2 x_1 + x_2 + x_3 \geq 2$.
The RUP steps proceeds as follows:
\begin{enumerate}
\item
We can see that $\obar{C} = 2 \obar{x}_1 + \obar{x}_2 + \obar{x}_3 \geq 3$, and this unit propagates assignment $\assign_1 = \{ \obar{x}_1 \}$.
\item
With this, constraint $C_1$ simplifies to $2 x_2 + \obar{x}_3 \geq 2$, and this unit propagates $x_2$, giving  $\assign_2 = \{ \obar{x}_1, x_2 \}$.
\item
  Constraint $C_2$ simplifies to $2 x_3 \geq 1$, which unit propagates $x_3$, giving $\assign_3 = \{ \obar{x}_1,  x_2, x_3 \}$.
\item
  Constraint $C_3$ simplifies to $ 0 \geq 3$, which is infeasible.
\end{enumerate}

\section{Pseudo-Boolean Implication Proofs}

A Pseudo-Boolean Implication Proof (PBIP) provides a systematic way to
prove that a PB formula $F$ is unsatisfiable.  It is given by a sequence of constraints, referred to as the {\em proof sequence}:
\begin{displaymath}
  C_1, C_2, \ldots, C_m, C_{m+1}, \ldots, C_t
\end{displaymath}  
such that the first $m$ constraints are those of formula $F$, while each {\em added} constraint $C_i$
for  $i > m$ follows by implication from the preceding constraints.
That is, 
\begin{eqnarray}
\bigwedge_{1 \leq j < i} \func{C_j} & \imply & \func{C_i} \label{eqn:proofsequence}
\end{eqnarray}
The proof completes with the addition of an infeasible constraint for $C_t$.
By the transitivity of implication, we have therefore proved that $F$ is not satisfiable.

Constraints $C_{i}$ with $i > m$, can be added in two different ways, corresponding to two different reasoning modes.
\begin{enumerate}
\item In {\em implication mode}, constraint $C_i$ follows by implication from at most two prior constraints in the  proof sequence.
  That is, for some $H_i \subseteq \{C_1, C_2,
  \ldots, C_{i-1}\}$ with $|H_i| \leq 2$ such that:
\begin{eqnarray}
\bigwedge_{C_j \in H_i} \func{C_j} & \imply & \func{C_i} \label{eqn:implicationmode}
\end{eqnarray}
Set $H_i$ is referred to as the {\em hint} for proof step $i$.
\item In \emph{RUP} mode, the new constraint is justified by reverse
  unit propagation.  Again, a sequence of hints is specified, where
  each hint is of either of the form $[C_j, \lit]$,
  where $j \leq i$ and $\lit$ is the unit
  literal propagated by this step, or of the form $[C_j]$, where $j \leq i$.
  When $j < i$, unit
  propagation is performed using constraint $C_j$, while for $j = i$,
  it is performed using $\obar{C}_i$, the negation of the target
  constraint.
  The final hint is of the form $[C_j]$.
  Note that if a single constraint unit propagates multiple literal, these are listed as separate steps.

\end{enumerate}

Unless ${\it P} = {\it NP}$, we cannot guarantee that a proof checker
can validate even a single implication step of a PBIP proof in polynomial time.
In particular, consider an equational constraint $C$ encoding an
instance of the subset sum problem, and let $C_{\leq}$ and $C_{\geq}$
denote its conversion into a pair of ordering constraints such that
$\func{C} = \func{C_{\leq}} \land \func{C_{\geq}}$.  Consider a PBIP
proof step to add the constraint $\obar{C}_{\leq}$ having the 
$C_{\geq}$ as the only hint.  Proving that
$\func{C_{\geq}} \imply \func{\obar{C}_{\leq}}$, requires proving that
$\func{C_{\leq}} \land \func{C_{\geq}} = \nil$, i.e., that $C$ is unsatisfiable.

On the other hand, checking the correctness of a PBIP proof can be
performed in {\em pseudo-polynomial} time, meaning that the complexity
will be bounded by a polynomially sized formula over the numeric
values of the integer parameters.  This can be done using binary
decision diagrams [BBH-2022].  In particular, an ordering constraint
over $n$ variables in coefficient-normalized form with constant $b$
will have a BDD representation with at most $b \cdot n$ nodes.  For an
implication proof step where the added constraints and the hints all
have constants less than or equal to $b$, the number of BDD operations
to validate the step will be $O(b^{2} \cdot n)$ when there is a single
hint and $O(b^{3} \cdot n)$ when there are two hints.  This complexity
is polynomial in $b$, but it would be exponential in the size of a
binary representation of $b$.  The number of BDD operations
for each unit propagation step in a RUP proof will be linear in the
size of the BDD and therefore $O(b \cdot n)$\@.


\section{Converting PBIP Proof into Clausal Proof}

We convert PBIP proofs into clausal proofs in the LRAT format using
{\em trusted} Binary Decision Diagrams, or TBDDs.  TBDDs extend
conventional BDDs by having their standard operations also generate proof steps.
We denote BDDs by their root nodes, using bold letters, e.g., $\nodeu$.
A TBDD $\trust{\nodeu}$ consists of the following:
\begin{itemize}
\item A BDD having root node $\nodeu$
\item A Boolean extension variable $u$ along with an associated
  proof clauses defining the semantic relation between $\nodeu$,  the node variable $x$, and 
  child nodes
  nodes $\nodeu_1$ and $\nodeu_0$
\item A proof of the unit clause $[u]$ indicating that the BDD will evaluate to 1 for any assignment that satisfies the input formula
\end{itemize}

We assume our trusted BDD package implements the following operations
\begin{description}
\item[$\fname{BDD}(C)$:] Generate a BDD representation of pseudo-Boolean constraint $C$
\item[$\fname{BDD\_AND}(\nodeu, \nodev)$:] Compute BDD $\nodew$ as the conjunction of BDDs $\nodeu$ and $\nodev$.  Also generate proof steps ending with the addition of the clause $[\obar{u} \lor \obar{v} \lor w]$ proving the $(u \land v) \imply w$.
\item[$\fname{BDD\_IMPLY}(\nodeu, \nodev)$:]
  Generate proof steps ending with the addition of the clause $[\obar{u} \lor v]$ indicating that $u \imply v$.
\item[$\fname{BDD\_FALSIFIES}(\assign, \nodeu)$:] For (possibly partial) assignment $\assign = \{\lit_1, \lit_2, \ldots, \lit_k\}$
  generate proof steps ending with the addition of the clause $[\obar{\lit}_1 \lor \obar{\lit}_2 \lor \cdots \lor \obar{\lit}_k \lor \obar{u}]$.
  This clause indicates
  that any total assignment consistent with $\assign$ will define a path in the BDD leading from root node $\nodeu$ to the leaf node representing false.
\item[$\fname{BDD\_SATISFIES}(\assign, \nodeu)$:] For (possibly partial) assignment $\assign = \{\lit_1, \lit_2, \ldots, \lit_k\}$
  generate proof steps ending with the addition of the clause $[\obar{\lit}_1 \lor \obar{\lit}_2 \lor \cdots \lor \obar{\lit}_k \lor u]$.
  This clause indicates
  that any total assignment consistent with $\assign$ will define a path in the BDD leading from root node $\nodeu$ to the leaf node representing true.
  
\end{description}

Our goal is the create a TBDD representation $\trust{\nodeu}_i$ for
each constraint $C_i$ in the proof sequence.  The final step will
generate a trusted BDD for the BDD leaf node representing false.  This
will cause the empty clause to be added to the proof.
When adding constraint $C_i$, its BDD
representation $\nodeu_i$ can be generated as $\fname{BDD}(C_i)$.  To upgrade
this to the trusted BDD $\trust{\nodeu}_i$ requires generating the unit clause $[u_i]$.
We assume that every prior proof constraint $C_{i'}$, with $i' < i$, has a TBDD representation $\trust{\nodeu}_{i'}$ with an associated unit clause
$[u_{i'}]$.

When $C_i$ is added by implication mode, generating its unit clause is
based on the constraints given as the hint.
If the hint consists of the
single constraint $C_{i'}$ we can make use of its TBDD representation
$\trust{\nodeu}_{i'}$, by performing the implication test
$\fname{BDD\_IMPLY}(\nodeu_{i'}, \nodeu_i)$, generating the clause
$[\obar{u}_{i'}, u_i]$.  Resolving this with the unit clause
$[u_{i'}]$ then gives the unit clause $[u_i]$.  When the hint consists
of two constraints $C_{i'}$ and $C_{i''}$, we can make use of their
TBDD representation $\trust{\nodeu}_{i'}$ and $\trust{\nodeu}_{i''}$.
That is, let $\nodew = \fname{BDD\_AND}(\nodeu_{i'}, \nodeu_{i''})$,
generating the clause
$[\obar{u}_{i'} \lor \obar{u}_{i''}  \lor w]$, and then
perform the implication test $\fname{BDD\_IMPLY}(w, \nodeu_i)$, generating the clause $[\obar{w} \lor u_i]$.
Resolving these clauses with the unit clauses for TBDDs
$\trust{\nodeu}_{i'}$ and $\trust{\nodeu}_{i''}$
yields the unit clause $[u_i]$.

Adding constraint $C_i$ via a sequence of RUP steps requires
converting its proof by contradiction into a conventional implication
proof.
Let $\nodeu_i$ denote the BDD representation of constraint
$C_i$.  For each literal $\lit$ that is unit propagated by a RUP step,
we add the clause $[u_i \lor \lit]$, indicating that literal $\lit$
will hold if the target constraint is falsified.  To do so for literal
$\lit_k$, suppose that we have clauses of the form $[u_i \lor
  \lit_{j}]$ for $1 \leq j \leq k$, and that unit propagation is based
either on constraint $D = C_{i'}$ for $i' < i$, represented by TBDD node
$\trust{\nodeu}_{i'}$ and denoted by literal $u_{i'}$, or based on
constraint $D = \obar{C}_{i}$ and denoted by literal $\obar{u}_i$.

Assignment $\assign = \{ \lit_1, \lit_2, \ldots, \lit_{k-1}, \obar{\lit}_{k} \}$
should cause $\simplify{D}{\assign}$ to be infeasible.
For $D = C_{i'}$, calling
$\fname{BDD\_FALSIFIES}(\assign, \nodeu_{i'})$ will generate the clause
$[\obar{\lit}_1 \lor \obar{\lit}_2 \lor \cdots \lor \obar{\lit}_{k-1} \lor \lit_k \lor \obar{u}_{i'}]$.
Resolving this with clauses of the form $[u_i \lor \lit_{j}]$ as well as the unit clause $[u_{i'}]$
will yield clause $[u_i \lor \lit_{k}]$.
For $D = \obar{C}_{i}$, calling
$\fname{BDD\_SATISFIES}(\assign, \nodeu_i)$ will generate the clause
$[\obar{\lit}_1 \lor \obar{\lit}_2 \lor \cdots \lor \obar{\lit}_{k-1} \lor \lit_k \lor u_i]$.
Resolving this with clauses of the form $[u_i \lor \lit_{j}]$
will yield clause $[u_i \lor \lit_{k}]$.
For the final step, no unit propagation occurs, and so the resolution steps will yield unit clause $[u_i]$,
completing the validation of constraint $C_i$.


%%\bibliography{references}

\end{document}
