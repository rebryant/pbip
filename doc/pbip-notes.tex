\documentclass{easychair}
%\documentclass[runningheads]{llncs}

\usepackage{latexsym}
%\usepackage{times}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{pict2e}
\usepackage{tikz}
%%\usepackage{pgfplots}
%%\pgfplotsset{compat=1.14}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{marvosym}
%\usepackage{hyperref}
%% Colored hyperlink 
\newcommand{\cref}[2]{\href{#1}{\color{blue}#2}}
%% Colored hyperlink showing link in TT font
% \newcommand{\chref}[1]{\href{#1}{\small\tt \color{blue}#1}}
\newcommand{\hcref}[1]{\cref{#1}{\small\tt #1}}
%% Change tt font
\usepackage{inconsolata}
\usepackage[T1]{fontenc}
\usepackage{alltt}
%% ccode- for displaying formatted C code (c2tex) 
\newenvironment{ccode}%
{\begin{alltt}}%
{\end{alltt}}

\bibliographystyle{abbrv}
%\bibliographystyle{splncs04}

%% Putting labels in pictures
\newcommand{\booland}{\land}
\newcommand{\boolor}{\lor}
\newcommand{\boolxor}{\oplus}
\newcommand{\boolnot}{\neg}
\newcommand{\tautology}{\top}
\newcommand{\nil}{\bot}
\renewcommand{\obar}[1]{\overline{#1}}
\newcommand{\lit}{\ell}
\newcommand{\ite}{\mbox{\it ITE}}
\newcommand{\restrict}[2]{#1|_{#2}}
\newcommand{\trust}[1]{\dot {#1}}
\newcommand{\assign}{\rho}
\newcommand{\simplify}[2]{#1|_{#2}}
\newcommand{\nassign}{\obar{\assign}}
\newcommand{\indices}{I}
\newcommand{\unit}{\mathit{Unit}}
\newcommand{\uprop}{\mathit{Uprop}}
\newcommand{\imply}{\Rightarrow}


\newcommand{\opname}[1]{\mbox{\sc #1}}
\newcommand{\andop}{\opname{And}}
\newcommand{\implyop}{\opname{Imply}}

\newcommand{\applyand}{\opname{ApplyAnd}}
\newcommand{\applyor}{\opname{ApplyOr}}
\newcommand{\applyimply}{\opname{ProveImplication}}

\newcommand{\turnstile}{\models}
\newcommand{\func}[1]{\llbracket#1\rrbracket}

\newcommand{\fname}[1]{\mbox{\small\sf #1}}

\newcommand{\lo}{\fname{Lo}}
\newcommand{\hi}{\fname{Hi}}
\newcommand{\var}{\fname{Var}}
\newcommand{\val}{\fname{Val}}
\newcommand{\xvar}[1]{#1}
\newcommand{\node}[1]{\mathbf{#1}}
\newcommand{\nodeu}{\node{u}}
\newcommand{\nodev}{\node{v}}
\newcommand{\nodew}{\node{w}}

% Code formatting
\newcommand{\showcomment}[1]{\texttt{/*} \textit{#1} \texttt{*/}}
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\keyif}{\keyword{if}}
\newcommand{\keyfor}{\keyword{for}}
\newcommand{\keyelse}{\keyword{else}}
\newcommand{\keyor}{\keyword{or}}
\newcommand{\keyreturn}{\keyword{return}}
%\newcommand{\assign}{\ensuremath{\longleftarrow}}

\definecolor{redorange}{rgb}{0.878431, 0.235294, 0.192157}
\definecolor{lightblue}{rgb}{0.552941, 0.72549, 0.792157}
\definecolor{clearyellow}{rgb}{0.964706, 0.745098, 0}
\definecolor{clearorange}{rgb}{0.917647, 0.462745, 0}
\definecolor{mildgray}{rgb}{0.54902, 0.509804, 0.47451}
\definecolor{softblue}{rgb}{0.643137, 0.858824, 0.909804}
\definecolor{bluegray}{rgb}{0.141176, 0.313725, 0.603922}
\definecolor{lightgreen}{rgb}{0.709804, 0.741176, 0}
\definecolor{darkgreen}{rgb}{0.152941, 0.776471, 0.172549}
\definecolor{redpurple}{rgb}{0.835294, 0, 0.196078}
\definecolor{midblue}{rgb}{0, 0.592157, 0.662745}
\definecolor{clearpurple}{rgb}{0.67451, 0.0784314, 0.352941}
\definecolor{browngreen}{rgb}{0.333333, 0.313725, 0.145098}
\definecolor{darkestpurple}{rgb}{0.396078, 0.113725, 0.196078}
\definecolor{greypurple}{rgb}{0.294118, 0.219608, 0.298039}
\definecolor{darkturquoise}{rgb}{0, 0.239216, 0.298039}
\definecolor{darkbrown}{rgb}{0.305882, 0.211765, 0.160784}
\definecolor{midgreen}{rgb}{0.560784, 0.6, 0.243137}
\definecolor{darkred}{rgb}{0.576471, 0.152941, 0.172549}
\definecolor{darkpurple}{rgb}{0.313725, 0.027451, 0.470588}
\definecolor{darkestblue}{rgb}{0, 0.156863, 0.333333}
\definecolor{lightpurple}{rgb}{0.776471, 0.690196, 0.737255}
\definecolor{softgreen}{rgb}{0.733333, 0.772549, 0.572549}
\definecolor{offwhite}{rgb}{0.839216, 0.823529, 0.768627}


\title{Notes on \\ Pseudo-Boolean Implication Proofs \\ Version of \today}

\author{Randal E. Bryant}
\institute{
Computer Science Department \\
Carnegie Mellon University, Pittsburgh, PA, United States\\
\email{Randy.Bryant@cs.cmu.edu}
}


\begin{document}

\maketitle

This notes describes some ideas on converting unsatisfiability proofs
for pseudo-Boolean (PB) constraints into clausal proofs based on the
DRAT proof system.

\section{Notation}

This section gives brief definitions of pseudo-Boolean constraints and their properties.
A more extensive introduction is provided by Gocht in his PhD thesis [Gocht-Phd-2022].

Consider a set of Boolean variables $X$.  For $x \in X$, {\em literal}
$\lit$ can denote either $x$ or its negation, written $\obar{x}$.  We
write $\obar{\lit}$ to denote $\obar{x}$ when $\lit = x$ and $x_i$ when
$\lit = \obar{x}$.

A {\em pseudo-Boolean constraint} is a linear expression, viewing
Boolean variables as ranging over integer values $0$ and $1$.  That
is, 
a constraint $C$ has the form
\begin{eqnarray}
\sum_{1 \leq i \leq n} a_i \lit_i & \# & b \label{eqn:pbconstraint}
\end{eqnarray}
where: 1) the relational operator $\#$ is $<$, $\leq$, $=$, $\geq$, or
$>$, and 2) the coefficients $a_i$, as well as the constant $b$, are
integers.
Constraints with relational operator $=$ are referred to as {\em equational constraints},
while others are referred to as {\em ordering constraints}.

Constraint $C$ denotes a Boolean function, written
$\func{C}$, mapping assignments to the set of variables $X$ to $1$
(true) or $0$ (false).  Constraints $C_1$ and $C_2$ are said to {\em
  equivalent} when $\func{C_1} = \func{C_2}$.
Constraint $C$ is said to be {\em infeasible} when $\func{C} = \bot$, i.e., it always evaluates $0$.
$C$ is said to be {\em trivial} when $\func{C} = \top$, i.e., it always evaluates to $1$.


As described in [Gocht-Phd-2022], the following are some properties of pseudo-Boolean constraints:
\begin{itemize}
\item Constraints with relational operators $<$, $\leq$, and $>$ can be
  converted to equivalent constraints with relational operator $\geq$.
\item
The logical negation of an ordering constraint $C$, written $\obar{C}$,
can also be expressed as a constraint.  That is, assume that $C$
has been converted to a form where it has relational operator $\geq$.
Then replacing $\geq$ by $<$ yields the negation of $C$.  
\item
A constraint $C$ with relational operator $=$ can be converted to the
pair of constraints $C_{\leq}$ and $C_{\geq}$, formed by replacing
$\#$ in (\ref{eqn:pbconstraint}) by $\leq$ and $\geq$, respectively.
These then satisfy $\func{C} = \func{C_{\leq}} \land \func{C_{\geq}}$.
\end{itemize}
We will generally
assume that constraints have relational operator $\geq$, since other
forms can be translated to it.  In some contexts, however, we will
maintain equational constraints 
intact, to avoid replacing it by two ordering constraints.


We consider two {\em normalized forms} for ordering constraints: A
{\em coefficient-normalized} constraint has only nonnegative
coefficients.  By convention, we require with this form that literal $\lit_i = x_i$ for any $i$ such that $a_i = 0$.
A {\em variable-normalized} constraint has only
positive literals.  Converting between the two forms is
straightforward using the identity $\obar{x}_i = 1-x_i$.  In reasoning
about PB constraints, the two forms can be used interchangeably.
Typically, the coefficient-normalized form is more convenient when
viewing a PB constraint as a logical expression, while the
variable-normalized form is more convenient when viewing a constraint
as an arithmetic expression.  In this document, we focus on the logical
aspects, giving the general form of constraint $C$ as
\begin{eqnarray}
\sum_{1 \leq i \leq n} a_{i} \lit_{i} & \geq & b \label{eqn:coeff-normalized}
\end{eqnarray}
with each $a_{i} \geq 0$, and with $\lit_{i} = x_i$ whenever $a_i = 0$.

Ordering constraint $C$ in coefficient-normalized form is trivial if and only
if $b \leq 0$.  Similarly, $C$ is infeasible if and only if
$b > \sum_{1 \leq i \leq n} {a_{i}}$.  By contrast, testing feasibility or triviality
of an equational constraint is not straightforward, in that an instance of the
subset sum problem [Garey] can be directly encoded as an equational
constraint.

An {\em assignment} is a mapping $\assign : X' \rightarrow \{0,1\}$,
for some $X' \subseteq X$.  The assignment is {\em total} when $X' =
X$ and {\em partial} when $X' \subset X$.  Assignment $\assign$ can
also be viewed as a set of literals, where $x_i \in \assign$ when
$\assign(x_i) = 1$ and $\obar{x}_i \in \assign$ when $\assign(x_i) = 0$.
A total assignment 

Some nomenclature regarding constraints of the form of
(\ref{eqn:coeff-normalized}) will prove useful.  The {\em constraint
  literals} are those literals $\lit_i$ such that $a_i \not = 0$.  A
{\em cardinality constraint} has $a_i \in \{0,1\}$ for $1 \leq i \leq
n$.  A cardinality constraint with $b=1$ is referred to as a {\em
  clause}: at least one of the constraint literals must be assigned 1
to satisfy the constraint.  A cardinality constraint with $\sum_{1\leq
  i\leq n} a_i = b$ is referred to as a {\em conjunction}: all of the
constraint literals must be assigned $1$ to satisfy the constraint.
Observe that any assignment $\assign$ can be viewed as a conjunction,
having coefficient $a_i = 1$ for each $\lit_i \in \assign$.  A
conjunction with for which $a_i = 1$ for just a single value of $i$ is
referred to as a {\em unit} constraint: it is satisfied if and only if
literal $\lit_i$ is assigned $1$.


%% Note that for
%% assignments $\assign_1$ and $\assign_2$ over disjoint sets of
%% variables $X_1$ and $X_2$, their union is logically equivalent to
%% their conjunction: $\func{\assign_1 \cup \assign_2} = \func{\assign_1}
%% \land \func{\assign_2}$.

%% We shall make use of constraints representing the negations of
%% assignments.  That is, the negation of assignment $\assign$, written
%% $\nassign$, is the clause:
%% $\sum_{\lit_i \in \assign} \obar{\lit}_i \;\geq\; 1$.

We let $\simplify{C}{\assign}$ denote the constraint resulting when $C$ is
simplified according assignment $\assign$.  That is, assume $\assign$ is defined over a set of variables $X'$ and
partition the indices $i$ for $1 \leq i \leq n$ into
three sets:
$I^{+}$, consisting of those indices $i$ such that $\lit_{i} \in \assign$,
$I^{-}$, consisting of those indices $i$ such that $\obar{\lit}_{i} \in \assign$,
and $I^{X}$ consisting of those indices $i$ such that $x_i \not \in X'$.
With this, $\simplify{C}{\assign}$ can be written as $\sum_{1 \leq i \leq n} a'_i \; \geq \; b'$
with $a'_i$ equal to $a_i$ for $i \in I^{X}$ and equal to $0$ otherwise, and with $b' = b - \sum_{i\in I^{+}} a_i$.


%% \begin{eqnarray}
%% \sum_{i \in I^{X}} a_{i} \lit_{i} & \geq & b - \sum_{i \in I^{+}} a_{i} \label{eqn:assigned}
%% \end{eqnarray}

%% **** This looks fishy ****
%% We will find cases where we want to condition a constraint $C$ based
%% on a partial assignment $\assign$, expressing the constraint $\assign
%% \imply C$.  In particular, if constraint $C$ is of the form
%% (\ref{eqn:coeff-normalized}), then $\assign \imply C$ can be written as the PB constraint
%% \begin{eqnarray}
%% \sum_{\lit_i \in \assign} b\, \obar{\lit}_i \;\; + \;\;  \sum_{1 \leq i \leq n} a_{i} \lit_{i} & \geq & b \label{eqn:implication}
%% \end{eqnarray}

A pseudo-Boolean {\em formula} $F$ is a set of pseudo-Boolean
constraints.  We say that $F$ is {\em satisfiable} when there is some
assignment $\assign$ that satisfies all of the constraints in $F$, and
{\em unsatisfiable} otherwise.  


\section{Pseudo-Boolean Implication Proofs}

A Pseudo-Boolean Implication Proof (PBIP) provides a systematic way to
prove that a PB formula $F$ is unsatisfiable.  It is given by a sequence of constraints, referred to as the {\em proof sequence}:
\begin{displaymath}
  C_1, C_2, \ldots, C_m, C_{m+1}, \ldots, C_t
\end{displaymath}  
such that the first $m$ constraints are those of formula $F$, while each {\em added} constraint $C_i$
for  $i > m$ follows by implication from the preceding constraints.
That is, 
\begin{eqnarray}
\bigwedge_{1 \leq j < i} \func{C_j} & \imply & \func{C_i} \label{eqn:proofsequence}
\end{eqnarray}
The proof completes with the addition of an infeasible constraint for $C_t$.
By the transitivity of implication, we have therefore proved that $F$ is not satisfiable.

Constraints $C_{i}$ with $i > m$, can be added in two different ways, corresponding to two different reasoning modes.
\begin{enumerate}
\item In {\em implication mode}, constraint $C_i$ follows by implication from at most two prior constraints in the  proof sequence.
  That is, for some $H_i \subseteq \{C_1, C_2,
  \ldots, C_{i-1}\}$ with $|H_i| \leq 2$ such that:
\begin{eqnarray}
\bigwedge_{C_j \in H_i} \func{C_j} & \imply & \func{C_i} \label{eqn:implicationmode}
\end{eqnarray}
Set $H_i$ is referred to as the {\em hint} for proof step $i$.
\item In {\em counterfactual} mode, the new constraint is justified
  via a proof by contradiction.  That is, $C_i$ is introduced as a
  {\em target constraint} 
and is followed by a sequence of {\em
    counterfactual constraints} $D^{i}_1, D^{i}_2, \ldots, D^{i}_k$
  that would hold if the target constraint were false.  (These constraints are not part of the proof sequence.) The final
  constraint $D^{i}_k$ is infeasible, thus showing by contradiction
  that the target constraint must hold.
  Each step in the counterfactual
  sequence must follow by implication from one or two constraints as a hint,
  where the hint $H^{i}_j$ for $D^{i}_j$ can contain the following:
  \begin{enumerate}
  \item A constraint $C_{i'}$ from the proof sequence.
  \item The negation of the target constraint $\obar{C}_i$
  \item An earlier counterfactual constraint within the same sequence $D^{i}_{j'}$ with $j' < j$.
  \end{enumerate}
  At least one of the constraints in the hint must be from the latter two categories.
  While in counterfactual mode, the proof can temporarily revert to
  implication mode, adding a constraint $C_{i'}$ to the proof sequence
  that follows by implication from at most two other constraints in the proof sequence.
  Once the final counterfactual constraint $D^{i}_k$ is given, the proof reverts to implication mode, and constraint $C_i$ can be used
  as the antecedent in subsequent proof steps.
\end{enumerate}

Unless ${\it P} = {\it NP}$, we cannot guarantee that a proof checker
can validate even a single implication step of a PBIP proof in polynomial time.
In particular, consider an equational constraint $C$ encoding an
instance of the subset sum problem, and let $C_{\leq}$ and $C_{\geq}$
denote its conversion into a pair of ordering constraints such that
$\func{C} = \func{C_{\leq}} \land \func{C_{\geq}}$.  Consider a PBIP
proof step to add the constraint $\obar{C}_{\leq}$ having the 
$C_{\geq}$ as the only hint.  Proving that
$\func{C_{\geq}} \imply \func{\obar{C}_{\leq}}$, requires proving that
$\func{C_{\leq}} \land \func{C_{\geq}} = \nil$, i.e., that $C$ is unsatisfiable.

On the other hand, checking the correctness of a PBIP proof can be
performed in {\em pseudo-polynomial} time, meaning that the complexity will
be bounded by a polynomially sized formula over the numeric values of
the integer parameters.  This can be done using binary decision
diagrams [BBH-2022].  In particular, an ordering constraint over $n$ variables in
coefficient-normalized form with constant $b$ will have a BDD
representation with at most $b \cdot n$ nodes.  For proof step where
the added constraints and the hints all have constants less than or equal
to $b$, the number of BDD operations to validate the step will be
$O(b^{2} \cdot n)$ when there is a single hint and $O(b^{3} \cdot n)$
when there are two hints.  This complexity is polynomial in $b$, but
it would be exponential in the size of a binary representation of $b$.

\section{(Reverse) Unit Propagation}

Consider constraint $C$ in coefficient-normalized form.  Literal
$\lit$ is {\em unit propagated} by $C$ when the assignment $\assign =
\{ \obar{\lit} \}$ causes the constraint $\simplify{C}{\assign}$ to become
infeasible.  As the name implies, a unit-propagated literal $\lit$ then becomes a unit constraint.
Observe that a single constraint can unit propagate
multiple literals.  For example, $4 x_1 + 3 \obar{x}_2 + x_3 \geq 6$
unit propagates both $x_1$ and $\obar{x}_2$.
For an ordering constraint $C$ in coefficent-normalized form
(\ref{eqn:coeff-normalized}), detecting which literals unit propagate
is straightforward.  Let $A = \sum_{1 \leq i \leq n} a_{i}$.  Then
literal $\lit_{i}$ unit propagates if and only if $A - a_{i} < b$,
i.e., $a_{i} > A - b$.  For example, the constraint $4 x_1 + 3
\obar{x}_2 + x_3 \geq 6$ has $A = 7$ and $b=6$, yielding $A-b=1$.
This justifies the unit propagations of both $x_1$ and $\obar{x}_2$.

For constraint $C$, we let $\unit(C)$ denote the set of literals it
unit propagates.  Often, by simplifying a constraint $C$ according to
a partial assignment $\assign$, the simplified constraint $\simplify{C}{\assign}$
will unit propagate new literals, given by $\unit(\simplify{C}{\assign})$.  These
literals can then be added to the partial assignment.  Formally,
define the operation $\uprop$ as  $\uprop(\assign, C) = \assign \cup \unit(\simplify{C}{\assign})$.
{\em Unit propagation} is then the process of
repeatedly applying this operation to a set of clauses to expand the
set of literals in a partial assignment.

The {\em reverse unit propagation} (RUP) proof rule [Gocht-Phd-2022]
uses unit propagation to prove that constraint can be added to formula
while preserving its set of satisfying assignments.  It closely
parallels the counterfactual reasoning mode of PBIP, using unit
propagation as the basic step for generating the counterfactual
constraints.  When adding clause $C_i$, each constraint $D^i_j$
in the counterfactual sequence represents the conjunction of a set of
literals $\assign_j$.  Let $\assign_0$ denote the conjunction of all
literals that have been derived as unit constraints previously.
For each $j$ with $1 \leq j < k$,
counterfactual assertion $\assign_j$ is derived either from some previous proof clause:
$\assign_j = \uprop(\assign_{j-1}, C_j)$ for $j < i$, or from the negated target:
$\assign_j = \uprop(\assign_{j-1}, \obar{C}_i)$.
The final contradiction occurs when $\simplify{C_k}{\assign_{k-1}}$ is infeasible.

\section{RUP Example}

As an example, consider the following three constraints:
\begin{center}
  \begin{tabular}{cllllll}
\toprule    
\makebox[1cm]{ID} & \multicolumn{6}{c}{Constraint} \\
\midrule
$C_1$ & \makebox[0.6cm][l]{$x_1$} & $+$ & \makebox[0.6cm][l]{$2 x_2$} & $+$ & \makebox[0.6cm][l]{$\obar{x}_3$} & \makebox[0.6cm][l]{$\geq 2$} \\
$C_2$ & $\obar{x}_1$ & $+$ & $\obar{x}_2$ & $+$ & $2 x_3$ & $\geq 2$ \\
$C_3$ & $x_1$ & $+$ & $2 \obar{x}_2$ & $+$ &  $3 \obar{x}_3$ & $\geq 3$ \\
\bottomrule
\end{tabular}
\end{center}
Our goal is to add the constraint $C = 2 x_1 + x_2 + x_3 \geq 2$ via RUP using these constraints, without any prior unit constraints.
RUP proceeds as follows:
\begin{enumerate}
\item
We can see that $\obar{C} = 2 \obar{x}_1 + \obar{x}_2 + \obar{x}_3 \geq 3$, and this unit propagates assignment $\assign_1 = \obar{x}_1 \geq 1$.
\item
With this, constraint $C_1$ simplifies to $2 x_2 + \obar{x}_3 \geq 2$, and this unit propagates $x_2$, giving  $\assign_2 = \obar{x}_1 + x_2 \geq 2$.
\item
  Constraint $C_2$ simplifies to $2 x_3 \geq 1$, which unit propagates $x_3$, giving $\assign_3 = \obar{x}_1 + x_2 + x_3 \geq 3$.
\item
  Constraint $C_3$ simplifies to $ 0 \geq 3$, which is infeasible.
\end{enumerate}

\section{Converting PBIP Proof into Clausal Proof}

We convert PBIP proofs into clausal proofs in the LRAT format using
{\em trusted} Binary Decision Diagrams, or TBDDs.  TBDDs extend
conventional BDDs by having their standard operations also generate proof steps.
We denote BDDs by their root nodes, using bold letters, e.g., $\nodeu$.
A TBDD $\trust{\nodeu}$ consists of the following:
\begin{itemize}
\item A BDD having root node $\nodeu$
\item A Boolean extension variable $u$ along with an associated
  proof clauses defining the semantic relation between $\nodeu$,  the node variable $x$, and 
  child nodes
  nodes $\nodeu_1$ and $\nodeu_0$
\item A proof of the unit clause $[u]$ indicating that the BDD will evaluate to 1 for any assignment that satisfies the input formula
\end{itemize}

We assume our trusted BDD package implements the following operations
\begin{description}
\item[$\fname{BDD}(C)$:] Generate a BDD representation of pseudo-Boolean constraint $C$
\item[$\fname{BDD\_AND}(\nodeu, \nodev)$:] Compute BDD $\nodew$ as the conjunction of BDDs $\nodeu$ and $\nodev$.  Also generate proof steps ending with the addition of the clause $[\obar{u} \lor \obar{v} \lor w]$ proving the $(u \land v) \imply w$.
\item[$\fname{BDD\_IMPLY}(\nodeu, \nodev)$:]
  Generate proof steps ending with the addition of the clause $[\obar{u} \lor v]$ indicating that $u \imply v$.
\item[$\fname{BDD\_OR}(\nodeu, \nodev)$:] Compute BDD $\nodew$ as the disjunction of BDDs $\nodeu$ and $\nodev$.  Also generate proof steps ending with the addition of the clause $[u \lor v \lor \obar{w}]$.  We use this when working with negated operands to prove that
$(\obar{u} \land \obar{v}) \imply \obar{w}$.
  
\end{description}

Our goal is the create a TBDD representation $\trust{\nodeu_i}$ for
each constraint $C_i$ in the proof sequence.  The final step will
generate a trusted BDD for the BDD leaf node representing false.  This
will cause the empty clause to be added to the proof.
When adding constraint $C_i$, its BDD
representation $\nodeu_i$ can be generated as $\fname{BDD}(C_i)$.  To upgrade
this to the trusted BDD $\trust{\nodeu_i}$ requires generating the unit clause $[u_i]$.
We assume that every prior proof constraint $C_{i'}$, with $i' < i$, has a TBDD representation $\trust{\nodeu_{i'}}$ with an associated unit clause
$[u_{i'}]$.

When $C_i$ is added by implication mode, generating its unit clause is
based on directly on the constraints given as the hint.
If the hint consists of the
single constraint $C_{i'}$ we can make use of its TBDD representation
$\trust{\nodeu_{i'}}$, by performing the implication test
$\fname{BDD\_IMPLY}(\nodeu_{i'}, \nodeu_i)$, generating the clause
$[\obar{u}_{i'}, u_i]$.  Resolving this with the unit clause
$[u_{i'}]$ then gives the unit clause $[u_i]$.  When the hint consists
of two constraints $C_{i'}$ and $C_{i''}$, we can make use of their
TBDD representation $\trust{\nodeu_{i'}}$ and $\trust{\nodeu_{i''}}$.
That is, let $\nodew = \fname{BDD\_AND}(\nodeu_{i'}, \nodeu_{i''})$,
generating the clause
$[\obar{u}_{i'} \lor \obar{u}_{i''}  \lor w]$, and then
perform the implication test $\fname{BDD\_IMPLY}(w, \nodeu_i)$, generating the clause $[\obar{w} \lor u_i]$.
Resolving these clauses with the unit clauses for TBDDs
$\trust{\nodeu_{i'}}$ and $\trust{\nodeu_{i''}}$
yields the unit clause $[u_i]$.

Adding constraint $C_i$ via a counterfactual sequence requires
converting its proof by contradiction into a conventional implication
proof.  We do so by constructing the implications in reverse order.
For each counterfactual constraint $D^i_j$ in the
sequence, where $1 \leq j \leq k$, let $\nodev_j =
\fname{BDD}(\obar{D}^i_j)$, the BDD representation of the negation of
the constraint.  By convention, we define $D^i_0 = \obar{C}_i$ and
also have $\nodev_0 = \nodeu_i$.  In processing counterfactual
constraint $D^{i}_j$, we assume that for any $j' < j$, we have already
generated proof clause $[\obar{v}_{j'} \lor u_i]$.  That is, the
negation of constraint $D^{i}_{j'}$ implies the target constraint
$C_i$.  For $j' = 0$, this clause is the tautology $[\obar{u}_i \lor u_i]$.

Processing counterfactual constraint $D^i_j$ then requires generating a proof of the clause 
$[\obar{v}_{j} \lor u_i]$.  Consider three cases for the hint of this step:
\begin{enumerate}
\item The hint consists of a single counterfactual constraint $D^{i}_{j'}$.  We therefore have the constraint
  $[\obar{v}_{j'} \lor u_i]$.
  Performing implication test
  $\fname{BDD\_IMPLY}(v_j, v_{j'})$
  yields the clause $[\obar{v}_j, v_{j'}]$.  Combining the two clauses by resolution yields the clause
  $[\obar{v}_{j} \lor u_i]$.

\item The hint consists of two constraints:
 a previous proof constraint $C_{i'}$, and
  a previous counterfactual constraint $D^{i}_{j'}$.
  We therefore have a TBDD representation $\trust{\nodeu_{i'}}$ with the unit clause $[u_{i'}]$, and a BDD representation $\nodev_{j'}$ with the clause
$[\obar{v}_{j'} \lor u_i]$  
  let $\nodew = \fname{BDD\_AND}(\nodeu_{i'}, \nodev_j)$, yielding the clause $[\obar{u}_{i'} \lor \obar{v}_j \lor w]$, and perform the implication test
  $\fname{BDD\_IMPLY}(\nodew, \nodev_{j'})$, yielding the clause $[\obar{w} \lor v_{j'}]$.  Resolving these four clauses yields 
$[\obar{v}_{j} \lor u_i]$.

  \item The hint consists of two previous counterfactual constraints.
    $D^{i}_{j'}$ and $D^{i}_{j''}$.  We therefore have clauses
    $[\obar{v}_{j'} \lor u_i]$ and $[\obar{v}_{j''} \lor u_i]$.
    Let $\nodew = \fname{BDD\_OR}(\nodev_{j'}, \nodev_{j''})$, yielding the clause
    $[v_{j'} \lor v_{j''} \lor \obar{w}]$, and perform the implication test $\fname{BDD\_IMPLY}(v_j, w)$, yielding the clause
    $[\obar{v}_j \lor w]$.  Resolving these four clauses yields the clause
    $[\obar{v}_{j} \lor u_i]$.
\end{enumerate}  
The final counterfactual
constraint $D^{i}_j$ yields a conflict, but since $\nodev_k$ is the
BDD representation of its negation, it will be the BDD leaf node
representing true.  Clause $[\obar{v}_{k} \lor u_i]$ will therefore
simplify to be the unit clause $[u_i]$, enabling the BDD
representation of constraint $C_i$ to be trusted.

%%\bibliography{references}

\end{document}
